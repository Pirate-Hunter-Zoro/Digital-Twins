# Project Gemini: Digital Twins for Clinical Prediction - Master Briefing

**Prepared for:** Mikey Ferguson
**Prepared by:** Entrapta & The Scientific Explorers
**Last Updated:** June 24, 2025

---

## 1. Project Overview & High-Level Workflow

The core objective of this project is to predict a patient's future clinical visit by identifying the most clinically relevant "nearest neighbors" from a large historical dataset. The project is structured as a series of experiments to determine the optimal methods for representing, vectorizing, and comparing patient trajectories.

The high-level workflow is as follows:

1. **Data Processing & Filtering:** Raw EHR data is processed into a patient-centric JSON format. The dataset is then filtered to include only patients who meet the minimum visit-count requirement for a given experiment.
2. **Modular Representation:** A patient's visit history is converted into a single string using a **selectable representation method** (e.g., `visit_sentence`, `bag_of_codes`). This is the core variable for **Experiment A**.
3. **Vectorize Histories:** The formatted history strings are converted into high-dimensional numerical vectors using a sentence-transformer model. This process is batched to prevent GPU memory overload.
4. **Find Nearest Neighbors:** Using a selectable distance metric (e.g., `cosine`, `euclidean`), the system calculates the "closest" `k` neighbors for each patient vector.
5. **Summarize & Predict:** A summary of the found neighbors is generated by an LLM. This summary, along with the target patient's history, is used to construct a final prompt for the LLM to predict the next visit's diagnoses, medications, and treatments.
6. **Evaluate:** The prediction is scored against the patient's actual visit data using our custom **Weighted Semantic Similarity Score**.

---

## 2. Current Status & Next Steps

**Current Status:** All major pipeline bugs have been resolved! The system is stable and has been successfully upgraded to be modular. We are currently running **Experiment A**, which compares the `visit_sentence` representation against the `bag_of_codes` representation.

**Next Steps:**

1. **Analyze Experiment A:** Once the current Slurm jobs complete, we will use `visualize_results.py` to compare the output files and determine which representation method yielded higher prediction scores, addressing **Hypothesis H3**.
2. **Implement More Representations:** Continue with Experiment A by implementing and testing the other representations from Dr. Paulus's plan (R1, R4, R5).
3. **Begin Experiment B:** Once the best representation is identified, we will move on to **Experiment B: Comparing Embedding Generators (E1-E6)**.

---

## 3. How to Run Experiments

All experiments are launched via configurable Slurm submission scripts (`.ssub` files).

1. **Configure:** Open the desired `.ssub` file (e.g., `run_visit_sentence.ssub`).
2. **Edit Parameters:** Change the shell variables at the top of the file to match the experiment you want to run (e.g., `REPRESENTATION`, `DISTANCE_METRIC`, `NUM_PATIENTS`).
3. **Submit:** Launch the job using `sbatch your_script_name.ssub`.

The output files (`.pkl` and `.json`) will be automatically named based on the parameters you choose, ensuring no data contamination between runs.

---

## 4. Overview of Project Python Scripts

* `main.py`: The main entry point. Reads parameters and orchestrates the pipeline.
* `parser.py`: **(Upgraded!)** Defines all command-line arguments, including the new `--representation_method` switch for Experiment A.
* `config.py`: **(Upgraded!)** Manages the global configuration state, now including `representation_method`.
* `compute_nearest_neighbors.py`: **(RE-ARCHITECTED!)** Now contains a modular `get_visit_histories` function that creates patient history strings based on the chosen `--representation_method`. It's the core of our experimental flexibility!
* `llm_helper.py` & `query_and_response.py`: Scripts for interacting with the LLM, including our intelligent neighbor-summarization step.
* `process_patient.py`: The core worker function for processing a single patient.
* `scripts/common/utils.py`: **(NEW!)** A centralized utility script housing the `turn_to_sentence` function to prevent circular imports.
* `evaluate.py`: Calculates our custom Weighted Semantic Similarity Score.
* `visualize_results.py`: Generates box plots and individual reports from a results file.
