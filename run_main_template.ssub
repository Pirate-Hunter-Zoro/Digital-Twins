# run_main_template.ssub
#!/bin/bash
#SBATCH --partition=c3_short
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8       # Let's start with more CPUs for embedding generation/multiprocessing
#SBATCH --nodes=1
#SBATCH --mem=32GB              # Adjust as needed, less if just running inference, more if generating embeddings
#SBATCH --time=04:00:00         # Give it more time per run
#SBATCH --output=logs/run_dt_%j_%x.stdout
#SBATCH --error=logs/run_dt_%j_%x.stderr
#SBATCH --job-name=dt_run_${VECTORIZER}_${DISTANCE} # Dynamic job name
#SBATCH --mail-user=mferguson@laureateinstitute.org
#SBATCH --mail-type=END

echo "Starting digital twin run for Vectorizer: $VECTORIZER, Distance: $DISTANCE"
echo "Current directory: $(pwd)"
echo "---"

module load Anaconda3/2022.05
source $(conda info --base)/etc/profile.d/conda.sh

conda run -n vllm_env python3 main.py \
    --vectorizer_method "$VECTORIZER" \
    --distance_metric "$DISTANCE" \
    --use_synthetic_data true # Or false once you're ready for real data

echo "Script finished for $VECTORIZER - $DISTANCE."