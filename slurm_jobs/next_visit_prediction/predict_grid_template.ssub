#!/bin/bash
#SBATCH --job-name=predict_visit
#SBATCH --output=logs/predict_%j_${REP}_${VEC}_${DIST}_${MODEL_NAME}_out.txt
#SBATCH --error=logs/predict_%j_${REP}_${VEC}_${DIST}_${MODEL_NAME}_err.txt
#SBATCH --partition=c3_short
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=32
#SBATCH --mem=80G
#SBATCH --gres=gpu:1
#SBATCH --time=9:00:00

# === âš™ï¸ Environment Setup ===
module load Python/3.11.5-GCCcore-13.2.0
source /opt/apps/easybuild/software/Anaconda3/2022.05/etc/profile.d/conda.sh
conda activate vllm_env

cd /mnt/dell_storage/homefolders/librad.laureateinstitute.org/mferguson/Digital-Twins

# === ðŸš€ Launch vLLM Server ===
echo "$(date): Starting vLLM server for model: $MODEL_NAME"
vllm serve $MODEL_PATH \
  --dtype float16 \
  --served-model-name $MODEL_NAME \
  --gpu-memory-utilization 0.5 \
  --host 0.0.0.0 \
  --max-model-len 5000 > logs/vllm_predict_${REP}_${VEC}_${DIST}_${MODEL_NAME}.log 2>&1 &

VLLM_PID=$!
trap "kill $VLLM_PID" EXIT

# Wait for vLLM to be ready
for i in {1..120}; do
  if curl -s http://localhost:8000/health | grep -q "OK"; then
    echo "$(date): vLLM server is healthy!"
    break
  fi
  sleep 2
done

# === ðŸ¤– Run Prediction Script ===
echo "$(date): Running predict_next_visit.py..."
$CONDA_PREFIX/bin/python scripts/llm/predict_next_visit.py \
  --representation_method $REP \
  --num_patients $PTS \
  --num_visits $VISITS \
  --vectorizer_method $VEC \
  --distance_metric $DIST \
  --num_neighbors $NBR \
  --model_name $MODEL_NAME

echo "$(date): Prediction job complete!"
