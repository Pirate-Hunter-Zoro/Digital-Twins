#!/bin/bash
#SBATCH --job-name=W2_Calibration_Run
#SBATCH --output=slurm_jobs/world_2_neighbor_analysis/logs/calibration_run_%j.out
#SBATCH --error=slurm_jobs/world_2_neighbor_analysis/logs/calibration_run_%j.err
#SBATCH --partition=c3_short
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=18
#SBATCH --mem=80G
#SBATCH --time=02:00:00

# --- 1. Set up the Magnificent Environment! ---
echo "üöÄ Activating the environment... Powering up!"
source /opt/apps/easybuild/software/Anaconda3/2022.05/etc/profile.d/conda.sh
conda activate dt_env
set -e # We stop if anything breaks! SCIENCE demands precision!

# --- 2. Launch the LLM Server in the Background! ---
echo "üß† Launching the vLLM Server... Waking up the big brain!"
# We're using the exact command from your VLLM.md file!
vllm serve unsloth/medgemma-27b-text-it-bnb-4bit \
  --served-model-name medgemma \
  --gpu-memory-utilization 0.9 \
  --host 0.0.0.0 \
  --max-model-len 5000 &

# We need to capture its little process ID so we can tell it when to stop!
VLLM_PID=$!
echo "‚úÖ vLLM Server started with PID: $VLLM_PID"

# --- 3. Wait for the Server to be Ready! ---
# We can't talk to it until it's ready to listen! Let's ping it!
echo "‚è≥ Waiting for the vLLM server to be ready... tick-tock..."
while ! curl -s http://localhost:8000/health; do
    echo "  - Server not ready yet, trying again in 5 seconds..."
    sleep 5
done
echo "‚úÖ Server is ready! Let the real experiment begin!"

# --- 4. Run the Main Calibration Script! ---
echo "üî¨ Running the main event! Calibrating on the sanity set!"
python scripts/world_2_neighbor_analysis/calibrate_on_sanity_set.py

# --- 5. The Grand Finale: Cleanup! ---
echo "üßπ The experiment is done! Time to clean up the lab!"
kill $VLLM_PID
echo "‚úÖ Successfully shut down the vLLM server."

echo "üéâ Glorious success! The entire calibration workflow is complete!"