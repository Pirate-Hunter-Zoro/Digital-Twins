#!/bin/bash
#SBATCH --job-name=generate_all_term_pairs_FINAL
#SBATCH --partition=c3_accel
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --mem=128G         
#SBATCH --time=7-00:00:00
#SBATCH --output=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs_out.txt
#SBATCH --error=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs_err.txt

# --- âœ¨ NEW: Safety trap to ensure cleanup! ---
trap "echo 'ðŸ›‘ SIGTERM received, killing vLLM Server...'; kill \$VLLM_PID" SIGTERM

echo "ðŸš€ Engaging ZOMBIE-PROOF Protocol! ðŸš€"

# --- ZOMBIE-BUSTING PRE-FLIGHT CHECK! ---
echo "Busting any zombie processes from previous runs..."
killall -q -u mferguson vllm || echo "No zombies found. Good!"

# --- Activate Conda and Load CUDA Module ---
source /opt/apps/easybuild/software/Anaconda3/2022.05/etc/profile.d/conda.sh
conda activate dt_env
module load CUDA/12.5.0

# --- The Magnificent Machine ---
echo "ðŸ§  Firing up a NEW vLLM server with Tensor Parallelism!"
# âœ¨ NEW: Using the number of requested GPUs for tensor parallel size!
vllm serve /media/scratch/mferguson/models/unsloth-medgemma-27b-text-it-bnb-4bit \
  --served-model-name medgemma \
  --tensor-parallel-size "$SLURM_GPUS_ON_NODE" \
  --dtype float16 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 4096 &

VLLM_PID=$!
echo "âœ… vLLM server started with PID: $VLLM_PID"
sleep 60 

echo "ðŸ¤– Unleashing the Synonym Invention Machine!"
python scripts/world_4_embedder_gauntlet/generate_term_pairs.py
echo "âœ… Synonym Invention Machine has finished its work!"

echo "ðŸ§¹ Shutting down the vLLM server (PID: $VLLM_PID)."
kill $VLLM_PID
wait $VLLM_PID 2>/dev/null

echo "ðŸŽ‰ AHAHAHA! VICTORY! The lab is clean, the machine is perfect, and the zombies are busted!"