#!/bin/bash
#SBATCH --job-name=generate_all_term_pairs_FINAL_FINAL
#SBATCH --partition=c3_accel
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=7-00:00:00
#SBATCH --output=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs.out
#SBATCH --error=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs.err

echo "ðŸš€ Engaging the 'Correct Magic Word' Protocol! ðŸš€"

# --- Activate Conda and Load the Correct CUDA Module! ---
source /opt/apps/easybuild/software/Anaconda3/2022.05/etc/profile.d/conda.sh
conda activate dt_env

# --- THE REAL FIX! ---
# Use the full module name you found with 'module spider cuda'
echo "Loading the correct CUDA module..."
module load cuda/12.5.0

# --- The Magnificent Machine (No more tricks needed!) ---
echo "ðŸ§  Firing up the vLLM server with MedGemma..."
vllm serve /media/scratch/mferguson/models/unsloth-medgemma-27b-text-it-bnb-4bit \
  --model-name medgemma \
  --dtype float16 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 4096 &

VLLM_PID=$!
echo "âœ… vLLM server started with PID: $VLLM_PID"
sleep 60

echo "ðŸ¤– Unleashing the Synonym Invention Machine!"
python scripts/world_4_embedder_gauntlet/generate_term_pairs.py
echo "âœ… Synonym Invention Machine has finished its work!"

echo "ðŸ§¹ Shutting down the vLLM server (PID: $VLLM_PID)."
kill $VLLM_PID
wait $VLLM_PID

echo "ðŸŽ‰ AHAHAHA! We spoke its language! The machine must obey!"