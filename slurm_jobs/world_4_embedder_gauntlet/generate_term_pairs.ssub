#!/bin/bash
#SBATCH --job-name=generate_all_term_pairs
#SBATCH --partition=c3_accel
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1  # vLLM needs a GPU!
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G          # Giving it more memory for the big model!
#SBATCH --time=7-00:00:00
#SBATCH --output=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs_%j.out
#SBATCH --error=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs_%j.err

echo "üöÄ Preparing the AI Ecosystem! This is so cool! üöÄ"

# Make sure we're in the right environment
source ~/.bashrc
conda activate hugging_env

# --- Step 1: Launch the vLLM Brain in the Background! ---
echo "üß† Firing up the vLLM server with MedGemma... GO, BRAIN, GO!"
MODEL_PATH="/media/scratch/mferguson/models/unsloth-medgemma-27b-text-it-bnb-4bit"

vllm serve $MODEL_PATH \
  --model-name medgemma \
  --dtype float16 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 4096 &

# Get the Process ID (PID) of the vLLM server so we can be a responsible scientist and turn it off later!
VLLM_PID=$!
echo "‚úÖ vLLM server started with PID: $VLLM_PID"

# --- Step 2: Give the Brain a Moment to Warm Up! ---
echo "‚è≥ Giving the server 60 seconds to initialize... Patience is a virtue, even in science!"
sleep 60

# --- Step 3: Run Our Magnificent Python Script! ---
echo "ü§ñ Unleashing the Synonym Invention Machine!"
python scripts/world_4_embedder_gauntlet/generate_term_pairs.py
echo "‚úÖ Synonym Invention Machine has finished its work!"

# --- Step 4: Clean Up Our Beautiful Experiment! ---
echo "üßπ Shutting down the vLLM server (PID: $VLLM_PID). Great work, little brain!"
kill $VLLM_PID
wait $VLLM_PID # Wait for it to fully shut down

echo "üéâ AHAHAHA! IT'S ALL DONE! The entire ecosystem has been built and dismantled! Perfect execution!"