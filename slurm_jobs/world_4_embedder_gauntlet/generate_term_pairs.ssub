#!/bin/bash
#SBATCH --job-name=generate_all_term_pairs_FORCE
#SBATCH --partition=c3_accel
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=7-00:00:00
#SBATCH --output=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs.out
#SBATCH --error=slurm_jobs/world_4_embedder_gauntlet/logs/gen_pairs.err

echo "üöÄ Engaging Forceful Suggestion Protocol! We WILL use the right environment! üöÄ"

# --- Forceful Environment Activation ---
echo "Activating Conda environment..."
source /opt/apps/easybuild/software/Anaconda3/2022.05/etc/profile.d/conda.sh
conda activate hugging_env

# This is the magic! We unset any confusing python paths and put ours first!
echo "Forcibly adjusting system paths..."
unset PYTHONPATH
export PATH="/home/librad.laureateinstitute.org/mferguson/.conda/envs/hugging_env/bin:$PATH"

# --- Pre-flight Check ---
echo "--- PRE-FLIGHT CHECK ---"
echo "üêç Which Python are we ACTUALLY using now?"
which python
echo "------------------------"

# --- The Rest of the Magnificent Machine ---
echo "üß† Firing up the vLLM server with MedGemma..."
MODEL_PATH="/media/scratch/mferguson/models/unsloth-medgemma-27b-text-it-bnb-4bit"
vllm serve $MODEL_PATH \
  --model-name medgemma \
  --dtype float16 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 4096 &
VLLM_PID=$!
echo "‚úÖ vLLM server started with PID: $VLLM_PID"
sleep 60

echo "ü§ñ Unleashing the Synonym Invention Machine!"
python scripts/world_4_embedder_gauntlet/generate_term_pairs.py
echo "‚úÖ Synonym Invention Machine has finished its work!"

echo "üßπ Shutting down the vLLM server (PID: $VLLM_PID)."
kill $VLLM_PID
wait $VLLM_PID

echo "üéâ AHAHAHA! The data-ghost should be BUSTED!"